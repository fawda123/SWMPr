{
    "collab_server" : "",
    "contents" : "######\n#' Import current station records from the CDMO\n#' \n#' Import current station records from the CDMO starting with the most current date\n#' \n#' @param station_code chr string of station, 7 or 8 characters\n#' @param Max numeric value for number of records to obtain from the current date\n#' @param param chr string for a single parameter to return, defaults to all parameters for a station type.\n#' @param trace logical indicating if import progress is printed in console\n#' \n#' @export\n#' \n#' @import httr\n#' \n#' @seealso \\code{\\link{all_params_dtrng}}, \\code{\\link{single_param}}\n#' \n#' @concept retrieve\n#' \n#' @return  Returns a swmpr object, all available parameters including QAQC columns\n#' \n#' @details \n#' This function retrieves data from the CDMO through the web services URL.  The computer making the request must have a registered IP address.  Visit the CDMO web services page for more information: \\url{http://cdmo.baruch.sc.edu/webservices.cfm}.  Function is the CDMO equivalent of \\code{exportAllParamsXMLNew} but actually uses \\code{\\link{all_params_dtrng}}, which is a direct call to \\code{exportAllParamsDateRangeXMLNew}.\n#' \n#' @examples\n#' \n#' \\dontrun{\n#' \n#' ## all parameters for a station, most recent\n#' all_params('hudscwq')\n#' \n#' }\nall_params <- function(station_code, Max = 100, param = NULL, trace = TRUE){\n\n  # url\n  serv <- \"http://cdmo.baruch.sc.edu/webservices2/requests.cfc?wsdl\"\n  \n  # get from most recent record\n  dat <- try({\n    httr::GET(serv, \n      query = list(\n        method = 'exportAllParamsXMLNew',\n        station_code = station_code, \n        recs = 1\n      )\n    )\n  }, silent = TRUE)\n  \n  # stop if retrieval error\n  if('try-error' %in% class(dat))\n    stop('Error retrieving data, check metadata for station availability.')\n\n  # parse reply from server \n  dat <- parser(dat)\n  \n  # starting date as character\n  dtrng <- dat$datetimestamp\n  dtrng <- strsplit(as.character(dtrng), ' ')[[length(dtrng)]][1]\n  dtrng <- c('01/01/1970', dtrng)\n    \n  # pass to all_params_dtrng\n  out <- all_params_dtrng(station_code, dtrng, param = param, trace = trace, Max = Max)\n\n  return(out)\n  \n}\n\n######\n#' Get CDMO records within a date range\n#' \n#' Get station records from the CDMO within a date range\n#' \n#' @param station_code chr string of station, 7 or 8 characters\n#' @param dtrng two element chr string, each of format MM/DD/YYYY\n#' @param param chr string for a single parameter to return, defaults to all parameters for a station type.\n#' @param trace logical indicating if import progress is printed in console\n#' @param Max numeric indicating maximum number of records to return\n#' \n#' @export\n#' \n#' @concept retrieve\n#' \n#' @return Returns a swmpr object, all parameters for a station type (nutrients, water quality, or meteorological) or a single parameter if specified.  QAQC columns are not provided for single parameters.\n#' \n#' @details \n#' This function retrieves data from the CDMO through the web services URL.  The computer making the request must have a registered IP address.  Visit the CDMO web services page for more information: \\url{http://cdmo.baruch.sc.edu/webservices.cfm}.  This function is the CDMO equivalent of \\code{exportAllParamsDateRangeXMLNew}.\n#' Download time may be excessive for large requests.\n#' \n#' @seealso \\code{\\link{all_params}}, \\code{\\link{single_param}}\n#' \n#' @examples\n#' \n#' \\dontrun{\n#' \n#' ## get all parameters within a date range\n#' all_params_dtrng('apaebwq', c('01/01/2013', '02/01/2013'))\n#' \n#' ## get single parameter within a date range\n#' all_params_dtrng('apaebwq', c('01/01/2013', '02/01/2013'), \n#'    param = 'do_mgl')\n#' \n#' }\nall_params_dtrng <- function(station_code, dtrng, param = NULL, trace = TRUE, Max = NULL){\n  \n  ##\n  # access CDMO web services\n\n  # timer\n  tictoc::tic()\n  \n  # url\n  serv <- \"http://cdmo.baruch.sc.edu/webservices2/requests.cfc?wsdl\"\n\n  # for initializing while loop\n  tz <- time_vec(station_code = station_code, tz_only = TRUE)\n  obsmin <- as.POSIXct(dtrng[1], format = '%m/%d/%Y', tz = tz)\n  end_obs <- obsmin + 1\n  \n  # object to fill\n  out_all <- NULL\n  \n  if(trace) cat('Importing...\\n\\n')\n  \n  # start loop\n  while(end_obs > obsmin){\n    \n    # arguments to pass to function on server\n    web_args = list(\n        method = 'exportAllParamsDateRangeXMLNew',\n        station_code = station_code,\n        mindate = dtrng[1],\n        maxdate = dtrng[2]\n        )\n    \n    # add a parameter argument if provided\n    if(!is.null(param)) web_args$param <- param\n    \n    # request data\n    dat <- try({\n      httr::GET(\n        serv,\n        query = web_args\n      )\n    }, silent = TRUE)\n    \n    # stop if retrieval error\n    if('try-error' %in% class(dat))\n      stop('Error retrieving data, check metadata for station availability.')\n    \n    # parse reply from server \n    out <- parser(dat)\n\n    # sometimes data request is good, but empty data frame returned\n    if(nrow(out) == 0)\n      stop('Empty data frame, check metadata for station availability')\n    \n    # type of parameter requested - wq, nut, or met, NOT the param argument\n    parm <- substring(station_code, 6)\n    nms <- param_names(parm)[[parm]]\n    \n    # format datetimestamp, sort, get relevant columns as data frame\n    out[, 'datetimestamp'] <- time_vec(out[, 'datetimestamp'], station_code)\n    out <- out[order(out$datetimestamp), ]\n    out <- data.frame(\n      datetimestamp = out$datetimestamp,\n      out[, tolower(names(out)) %in% nms, drop = FALSE],\n      row.names = 1:nrow(out)\n      )\n    names(out) <- tolower(names(out))\n\n    # get new loop \n    end_obs <- min(out$datetimestamp)\n    max_obs <- max(out$datetimestamp)\n\n    # progress\n    if(trace) cat('\\t', as.character(as.Date(max_obs) - 1), 'to', as.character(as.Date(end_obs)), '\\n')\n    \n    # exit if no new data\n    if(!is.null(out_all)){\n      if(end_obs == min(out_all$datetimestamp)) break\n    }\n\n    # append to output\n    out_all <- rbind(out_all, out)\n    out_all <- unique(out_all[order(out_all$datetimestamp), ])\n\n    if(!is.null(Max)){\n      if(nrow(out_all) >= Max){  \n        out_all <- out_all[(1 + nrow(out_all) - Max):nrow(out_all), ]\n        break\n      }\n    }\n    \n    # new date ranges\n    dtrng[2] <- as.character(as.Date(end_obs))\n    dtrng[2] <- paste0(substr(dtrng[2], 6, nchar(dtrng[2])), '/', substr(dtrng[2], 1, 4))\n    dtrng[2] <- gsub('-', '/', dtrng[2])\n    \n  }\n  \n  # sort by date, then remove duplicates (there will be overlaps)\n  # data columns as numeric\n  parms <- nms[!grepl('^f_', nms)]\n  out <- out_all\n  out[, names(out) %in% parms] <- apply(out[, names(out) %in% parms, drop = FALSE], 2, as.numeric)\n  row.names(out) <- 1:nrow(out)\n  \n  # convert to swmpr class\n  out <- swmpr(out, station_code)\n  \n  if(trace){\n    cat('\\n')\n    cat(nrow(out), 'records, ')\n    tictoc::toc()\n    }\n  \n  # return output\n  return(out)\n  \n}\n\n######\n#' Get CDMO records for a single parameter\n#' \n#' Get stations records from the CDMO for a single parameter starting with the most current date\n#' \n#' @param station_code chr string of station, 7 or 8 characters\n#' @param Max numeric value for number of records to obtain from the current date\n#' @param param chr string for a single parameter to return.\n#' @param trace logical indicating if import progress is printed in console\n#' \n#' @import XML\n#' \n#' @concept retrieve\n#' \n#' @export\n#' \n#' @return Returns a swmpr object with one parameter.  QAQC columns are not provided.\n#' \n#' @details \n#' This function retrieves data from the CDMO through the web services URL. The computer making the request must have a registered IP address.  Visit the CDMO web services page for more information: \\url{http://cdmo.baruch.sc.edu/webservices.cfm}.  This function is the CDMO equivalent of \\code{exportSingleParamXML}.\n#' \n#' @seealso \\code{\\link{all_params}}, \\code{\\link{all_params_dtrng}}\n#' \n#' @examples\n#' \n#' \\dontrun{\n#' \n#' ## single parameter for a station, most recent\n#' single_param('hudscwq', 'do_mgl')\n#' \n#' }\nsingle_param <- function(station_code, param, Max = 100, trace = TRUE){\n\n  ##\n  # access CDMO web services\n  \n  # url\n  serv <- \"http://cdmo.baruch.sc.edu/webservices2/requests.cfc?wsdl\"\n  \n  # request data\n  dat <- try({\n    httr::GET(\n      serv,\n      query = list(\n        method = 'exportSingleParamXMLNew',\n        station_code = station_code,\n        param = param,\n        recs = 1\n      )\n    )\n  }, silent = TRUE)\n  \n  # stop if retrieval error\n  if('try-error' %in% class(dat))\n    stop('Error retrieving data, check metadata for station availability.')\n  \n  # parse reply from server \n  dat <- parser(dat)\n  \n  # sometimes data request is good, but empty data frame returned\n  if(nrow(dat) == 0)\n    stop('Empty data frame, check metadata for station availability')\n  \n  # starting date as character\n  dtrng <- dat$datetimestamp\n  dtrng <- strsplit(as.character(dtrng), ' ')[[length(dtrng)]][1]\n  dtrng <- c('01/01/1970', dtrng)\n    \n  # pass to all_params_dtrng\n  out <- all_params_dtrng(station_code, dtrng, param = param, trace = trace, Max = Max)\n\n  return(out)\n  \n  # convert to swmpr class\n  out <- swmpr(out, station_code)\n  \n  # return output\n  return(out)\n  \n}\n\n######\n#' Import local CDMO data\n#' \n#' Import local data that were obtained from the CDMO through the zip downloads feature\n#' \n#' @param  path chr string of full path to .csv files with raw data, can be a zipped or unzipped directory where the former must include the .zip extension\n#' @param  station_code chr string of station to import, typically 7 or 8 characters including wq, nut, or met extensions, may include full name with year, excluding file extension\n#' @param  trace logical indicating if progress is sent to console, default \\code{FALSE}\n#' \n#' @concept retrieve\n#' \n#' @export\n#' \n#' @importFrom utils read.csv unzip\n#' \n#' @return Returns a swmpr object with all parameters and QAQC columns for the station.  The full date range in the raw data are also imported.\n#' \n#' @details \n#' The function is designed to import local data that were downloaded from the CDMO outside of R. This approach works best for larger data requests, specifically those from the zip downloads feature in the advanced query section of the CDMO. The function may also work using data from the data export system, but this feature has not been extensively tested. The downloaded data will be in a compressed folder that includes multiple .csv files by year for a given data type (e.g., apacpwq2002.csv, apacpwq2003.csv, apacpnut2002.csv, etc.). The import_local function can be used to import files directly from the compressed folder or after the folder is decompressed.  In the former case, the requested files are extracted to a temporary directory and then deleted after they are loaded into the current session.  An example dataset is available online to illustrate the format of the data provided through the zip downloads feature.  See the link below to access these data.  All example datasets included with the package were derived from these raw data.\n#' \n#' Occasionally, duplicate time stamps are present in the raw data.  The function handles duplicate entries differently depending on the data type (water quality,  weather, or nutrients).  For water quality and nutrient data, duplicate time stamps are simply removed.  Note that nutrient data often contain replicate samples with similar but not duplicated time stamps within a few minutes of each other.  Replicates with unique time stamps are not removed but can be further processed using \\code{\\link{rem_reps}}.  Weather data prior to 2007 may contain duplicate time stamps at frequencies for 60 (hourly) and 144 (daily) averages, in addition to 15 minute frequencies.  Duplicate values that correspond to the smallest value in the frequency column (15 minutes) are retained.  \n#' \n#' Zip download request through CDMO: \\url{http://cdmo.baruch.sc.edu/aqs/zips.cfm}\n#' \n#' Example dataset: \\url{https://s3.amazonaws.com/swmpexdata/zip_ex.zip}\n#' \n#' @seealso \\code{\\link{all_params}}, \\code{\\link{all_params_dtrng}}, \\code{\\link{rem_reps}}, \\code{\\link{single_param}}\n#' \n#' @examples\n#' \n#' \\dontrun{\n#' ## this is the path for csv example files, decompressed\n#' path <- 'C:/this/is/my/data/path'\n#'\n#' ## import, do not include file extension\n#' import_local(path, 'apaebmet') \n#' \n#' ## this is the path for csv example files, zipped folder\n#' path <- 'C:/this/is/my/data/path.zip'\n#'\n#' ## import, do not include file extension\n#' import_local(path, 'apaebmet') \n#' }\nimport_local <- function(path, station_code, trace = FALSE){\n  \n  # add .zip if not present\n  if(file.exists(paste0(path, '.zip'))){\n      path <- paste0(path, '.zip')\n    }\n  \n  # check if file exists \n  if(!file.exists(path)){\n    stop('Path does not exist')\n  }\n\n  # check if qualifiers are present in station_code\n  if(!grepl('wq|met|nut', station_code))\n    stop('station_code must include wq, met, or nut')\n  \n  # check if path is zipped\n  zips <- grepl('\\\\.zip$', path)\n  \n  # remove file extension if present, lower case\n  station_code <- tolower(gsub('\\\\.csv$', '', station_code))\n  \n  ##\n  # find station files in path\n  \n  # for zipped\n  if(zips){\n    \n    # get the file names in the zipped folder\n    # check if the requested files exist\n    file_nms <- unzip(path, list = TRUE)$Name\n    expr <- paste0(station_code, '.*', '\\\\.csv$')\n    files_in <- grep(expr, file_nms, value = TRUE, ignore.case = TRUE)\n    if(length(files_in) == 0) stop('File(s) not found.')\n    \n    # extract to temporary file\n    tmp_fl <- tempfile()\n    unzip(path, files = files_in, exdir = tmp_fl)\n    files_in <- dir(tmp_fl, recursive = TRUE)\n    \n    # reassign path to temporary file\n    path <- tmp_fl\n    \n  # for unzipped    \n  } else {\n\n    file_nms <- dir(path)\n    expr <- paste0('^', station_code, '.*', '\\\\.csv$')\n  \n  }\n\n  files_in <- grep(expr, file_nms, value = TRUE, ignore.case = TRUE)\n  if(length(files_in) == 0) stop('File(s) not found.')\n\n  station_code <- tolower(station_code)\n  \n  # import all data files for a station\n  dat <- vector('list', length(files_in))\n  names(dat) <- gsub('.csv', '', files_in)\n  \n  if(trace) cat('Loading files...\\n\\n')\n\n  for(file_in in files_in){\n    \n    if(trace) cat(file_in, '\\t')\n    \n    ##\n    # import\n \n    # import file, try using read.csv, else readlines\n    tmp <- try({\n      read.csv(file.path(path, file_in), stringsAsFactors = FALSE)\n    }, silent = TRUE)\n    \n    if('try-error' %in% class(tmp)){\n      raw <- readLines(file.path(path, file_in))\n      keep_lines <- grep(paste0('^', station_code), raw)\n      tmp <- raw[keep_lines]\n      tmp <- strsplit(tmp, ',')\n      tmp <- do.call('rbind', tmp)\n      tmp <- data.frame(tmp, stringsAsFactors = FALSE)\n      names(tmp)  <- strsplit(\n        gsub('[\"\\\\\"]', '', raw[keep_lines[1] - 1]),\n        ',')[[1]] \n    }\n    \n    names(tmp) <- tolower(names(tmp))\n    \n    # remove stationcode, isswmp columns\n    tmp <- tmp[, !names(tmp) %in% c('stationcode', 'isswmp')]\n    \n    # convert date time to posix\n    names(tmp)[grep('datetimestamp', names(tmp), ignore.case = TRUE)] <- 'datetimestamp'\n    tmp$datetimestamp <- time_vec(tmp$datetimestamp, station_code)\n    \n    # append to output list\n    nm <-  gsub('.csv', '', file_in)\n    dat[[nm]] <- tmp\n    \n    }\n\n  # remove temporary files if zips\n  if(zips) unlink(tmp_fl, recursive = TRUE)\n  \n  ##\n  # column names for each parameter type, used to subset combined data\n  # kept as upper case here because improted data will match, changed to lower below\n\n  # names to use\n  parm <- substring(station_code, 6)\n  parm <- gsub('[0-9.*]', '', parm)\n  nms <- param_names(parm)[[parm]]\n  \n  ##\n  # deal with duplicate time stamps depending on data type\n  \n  out <- do.call('rbind', dat)\n  \n  # if duplicated timestamps and met, keep those with minimum value in frequency\n  if('met' %in% parm & any(duplicated(out$datetimestamp)) & 'frequency' %in% names(out)){\n    \n    min_step <- as.character(min(as.numeric(unique(out$frequency))))\n    out <- out[out$frequency %in% min_step, ]\n    \n    # sometimes duplicates still remain at same frequency\n    out <- out[!duplicated(out$datetimestamp),]  \n    \n  }\n  \n  # remove duplicate time stamps from wq and nut data\n  if(any(c('nut', 'wq') %in% parm) & any(duplicated(out$datetimestamp))){\n    \n    out <- out[!duplicated(out$datetimestamp),]  \n    \n  }\n  \n  # remove rows with no datetimestamp\n  out <- out[!is.na(out$datetimestamp), ]\n  \n  # convert output to data frame\n  # retain only relevant columns\n  out <- data.frame(\n    datetimestamp = out$datetimestamp,\n    out[, names(out) %in% nms], \n    row.names = seq(1, nrow(out))\n    )\n \n  # make sure relevant columns are numeric\n  parameters <- grep('datetimestamp|^f_|^c_', names(out), invert = TRUE, value = TRUE)\n  out[, parameters] <- suppressWarnings(\n    lapply(out[, parameters], function(x) as.numeric(as.character(x)))\n    )\n  \n  # names as lower case\n  names(out) <- tolower(names(out))\n\n  # remove date from station_code, convert to swmpr class\n  station_code <- gsub('[0-9]*$', '', station_code)\n  out <- swmpr(out, station_code)\n  \n  if(trace) cat('\\n\\nData imported...')\n  \n  # return data frame\n  return(out)\n    \n}\n\n######\n#' Obtain metadata for all stations\n#' \n#' Obtain a \\code{\\link[base]{data.frame}} of metadata for all SWMP stations.\n#' \n#' @export\n#' \n#' @return A \\code{data.frame} of SWMP metadata\n#' \n#' @concept retrieve\n#' \n#' @details This function retrieves data from the CDMO web services.  The computer making the request must have a registered IP address.  Visit the CDMO web services page for more information: \\url{http://cdmo.baruch.sc.edu/webservices.cfm}. This is the CDMO equivalent of \\code{exportStationCodesXML}.\n#' \n#' @examples\n#' \\dontrun{\n#' \n#' ## retrieve metadata for all sites\n#' site_codes()\n#' \n#' }\nsite_codes <- function(){\n  \n  # access CDMO web services\n  serv <- \"http://cdmo.baruch.sc.edu/webservices2/requests.cfc?wsdl\"\n\n  # get all station codes\n  reply <- httr::GET(\n    serv,\n    query = list(method = 'exportStationCodesXMLNew'),\n    )\n\n  # parse reply from server\n  out <- parser(reply)\n  out$params_reported <- tolower(out$params_reported)\n  \n  # return output\n  return(out)\n  \n}\n\n######\n#' Obtain metadata for a single reserve\n#'\n#' Get metadata for all the stations at a single SWMP reserve\n#' \n#' @param nerr_site_id chr string of site, three letters\n#' \n#' @concept retrieve\n#' \n#' @export\n#' \n#' @return An abbreviated \\code{data.frame} of the SWMP metadata for the requested site\n#' \n#' @details This function retrieves data from the CDMO web services.  The computer making the request must have a registered IP address.  Visit the CDMO web services page for more information: \\url{http://cdmo.baruch.sc.edu/webservices.cfm}. This function is the CDMO equivalent of \\code{NERRFilterStationCodesXMLNew}.\n#' \n#' @examples\n#' \\dontrun{\n#' \n#' ## retrieve metadata for all stations at a site\n#' site_codes_ind('apa')\n#' \n#' }\nsite_codes_ind <- function(nerr_site_id){\n  \n  # access CDMO web services\n  serv <- \"http://cdmo.baruch.sc.edu/webservices2/requests.cfc?wsdl\"\n\n  # get all station codes\n  reply <- httr::GET(\n    serv,\n    query = list(  \n      method = 'NERRFilterStationCodesXMLNew',\n      NERRFilter = nerr_site_id\n    )\n  )\n\n  # parse reply from server\n  out <- parser(reply)\n  out$params_reported <- tolower(out$params_reported)\n  \n  # return output\n  return(out)\n  \n}\n    ",
    "created" : 1517776758089.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1825739278",
    "id" : "651F3DC4",
    "lastKnownWriteTime" : 1517777150,
    "last_content_update" : 1517777150,
    "path" : "C:/proj/swmpr/R/swmpr_retrieval.R",
    "project_path" : "R/swmpr_retrieval.R",
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}